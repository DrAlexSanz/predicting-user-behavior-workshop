{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkZkWWyAdlLT",
    "outputId": "17308440-9b0c-4554-ff6f-b50b15fffdc4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "!pip install torch_geometric\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install torchviz\n",
    "!pip install matplotlib\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRcM339FdzsX"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "TRAIN_PD_PATH = f\"{DATA_DIR}/2019-Oct_small.csv\"\n",
    "TARGETS_PD_PATH = f\"{DATA_DIR}/2019-Nov_train_target.csv\"\n",
    "TEST_TARGETS_PATH = f\"{DATA_DIR}/test_target.npy\"\n",
    "TARGET_LABELS = f'{DATA_DIR}/target_brands.npy'\n",
    "USER_IDS = f'{DATA_DIR}/user_ids.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44UT4g-ldz24",
    "outputId": "5d5d3c84-878d-4bfc-96d0-460d49520416"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7An1TIRydz6I"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_df = pd.read_csv(TRAIN_PD_PATH)\n",
    "    target_df = pd.read_csv(TARGETS_PD_PATH)\n",
    "    test_targets_np = np.load(TEST_TARGETS_PATH)\n",
    "    target_labels = np.load(TARGET_LABELS, allow_pickle=True)\n",
    "    user_ids = np.load(USER_IDS)\n",
    "\n",
    "    return train_df, target_df, test_targets_np, target_labels, user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJuYtdu9dz8z"
   },
   "outputs": [],
   "source": [
    "train_df, target_df, targets, target_labels, users_in_target = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "EzNILAtudz_O",
    "outputId": "78a2b3e9-17b5-4a3f-e7ae-500f1be0f55f"
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJv_fH0GeHeU"
   },
   "outputs": [],
   "source": [
    "target_df = target_df[target_df['user_id'].isin(train_df['user_id'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIpWahSceHhN"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, target_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybFXS80Z6Pi4"
   },
   "source": [
    "# Create artificial IDs for users and brands\n",
    "\n",
    "In a few moments we'll be using the PyG library. We must create some objects required by the library to represent our graph. First, we will map users and brands to artificial integer IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNP3DwTvy5rw",
    "outputId": "f562f008-f2b1-4ba2-a84b-85aa38dd6e3f"
   },
   "outputs": [],
   "source": [
    "users_in_target.shape, train_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeWTLNUMeHml",
    "outputId": "28f8560c-d6f8-4217-c66b-c2c2119a8738"
   },
   "outputs": [],
   "source": [
    "unique_user_ids = pd.DataFrame(data={\n",
    "    'user_id': users_in_target,\n",
    "    'mapped_user_id': pd.RangeIndex(len(users_in_target)),\n",
    "})\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_ids.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQsdmO7-eHov",
    "outputId": "1fd73fd8-e1d2-4fc7-a740-3ed001b28b6b"
   },
   "outputs": [],
   "source": [
    "unique_brands = train_df['brand'].unique()\n",
    "unique_brands = pd.DataFrame(data={\n",
    "    'brand': unique_brands,\n",
    "    'mapped_brand': pd.RangeIndex(len(unique_brands)),\n",
    "})\n",
    "print(\"Mapping of brands to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UUFfXd56oBb"
   },
   "source": [
    "Next, we merge the IDs with our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qs0rUy-z6li_"
   },
   "outputs": [],
   "source": [
    "purchases_user_id = pd.merge(train_df['user_id'], unique_user_ids,\n",
    "                            left_on='user_id', right_on='user_id', how='left')\n",
    "purchases_brand = pd.merge(train_df['brand'], unique_brands,\n",
    "                            left_on='brand', right_on='brand', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAwhrtpa64jF"
   },
   "source": [
    "We switch to representing our graph by only the artificial IDs, by taking matching user ID and brand ID of each transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pCyAD_760VX"
   },
   "outputs": [],
   "source": [
    "purchases_user_id = torch.from_numpy(purchases_user_id['mapped_user_id'].values)\n",
    "purchases_brand = torch.from_numpy(purchases_brand['mapped_brand'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4H2vwdA7Mof"
   },
   "source": [
    "# Create the HeteroData object\n",
    "\n",
    "Now, we finally create the native PyG object representing our graph. It's called HeteroData because we have a few different node types inside the graph. First, we merge the matching user and brand ids into a 2d numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dG96rtwjeb_R",
    "outputId": "2080a22d-2e23-46bd-8658-d22bbaef9bc2"
   },
   "outputs": [],
   "source": [
    "edge_index_user_to_brand = torch.stack([purchases_user_id, purchases_brand], dim=0)\n",
    "print(edge_index_user_to_brand.size())\n",
    "# assert edge_index_user_to_brand.size() == (2, 1669365)\n",
    "print()\n",
    "print(\"Final edge indices pointing from users to brands:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_user_to_brand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTphaswC7lKG"
   },
   "source": [
    "Then, we create an undirected HeteroData object.\n",
    "We need to name the main relationship between **users** and **brands**. We call it **buys** to reflect the relationship \"user A buys brand B\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iriEXw5recGV"
   },
   "outputs": [],
   "source": [
    "num_users = len(unique_user_ids)\n",
    "num_brands = len(unique_brands)\n",
    "\n",
    "data = HeteroData()\n",
    "data[\"user\"].node_id = torch.arange(num_users)\n",
    "data[\"brand\"].node_id = torch.arange(num_brands)\n",
    "\n",
    "#give some name to the relationship between user nodes and brand nodes\n",
    "data[\"user\", \"buys\", \"brand\"].edge_index = edge_index_user_to_brand\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Graph with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "_nzZhDo2C9_D",
    "outputId": "3f988bbc-3548-41d0-c572-6135b81ff92a"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "subgraph = edge_index_user_to_brand[:, :200].T.numpy()\n",
    "\n",
    "user2name = {x:f'user{x}' for x in subgraph[:, 0]}\n",
    "brand2name = {x:f'brand{x}' for x in subgraph[:, 1]}\n",
    "\n",
    "named_subgraph = [(user2name[start], brand2name[end]) for start, end in subgraph]\n",
    "\n",
    "g = nx.from_edgelist(named_subgraph)\n",
    "g = nx.DiGraph(g)\n",
    "\n",
    "nx.draw(g, node_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wVvi-9HXA9q",
    "outputId": "6c98bac2-c5a1-40b3-f303-0f7a55b9e448"
   },
   "outputs": [],
   "source": [
    "g.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsQwmM9JXFm6"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "We want to color the nodes to show which are USERS, and which are BRANDS. Create a `color_map` list with strings: 'red' for users, and 'green' for brands, to match the ordering of USER and BRAND nodes in `g.nodes` above.\n",
    "\n",
    "The result should look like this:\n",
    "`color_map = ('green', 'red', 'green', 'red', ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "4NZ0T62PXEb6"
   },
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "\n",
    "color_map = ['green' if x.startswith('brand') else 'red' for x in g.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "qI_GCAp7XL_8",
    "outputId": "05148121-8e40-4fb6-eafd-8c9179a6cd26"
   },
   "outputs": [],
   "source": [
    "#BRANDS are GREEN\n",
    "#USERS are RED\n",
    "nx.draw(g, node_size=40, node_color=color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SqPSemh5C1q"
   },
   "source": [
    "#Define the Splits\n",
    "\n",
    "Now, we need to define how our data will be split during training:\n",
    "\n",
    "\n",
    "\n",
    "*   `num_val` - what portion of the graph we want to validate on during training\n",
    "*   `num_test` - what portion of the graph we want to use for testing (it's 0.0 because we want to do a full prediction for all users during test)\n",
    "* `disjoint_train_ratio=0.3` - 30% of edges will be used as training targets (0 or 1 values will teach the model whether it should predict an edge or not between a given pair of nodes). 70% of edges will be used for aggregating neighbors and walking over the graph.  \n",
    "* `neg_sampling_ratio=2.0` - non-existent edges will be created as well (to be used as negative examples during validation) with a ratio of 2 non-existent edges to 1 existing edge\n",
    "* `add_negative_train_samples=False` - negative edges during training will not be generated beforehand, but will be generated on-the-fly\n",
    "* `edge_types` - our chosen name for the user-brand relationship\n",
    "* `rev_edge_types` - we want to go from users to brands, but also from brands to users (two-way connections in the graph). We call it a *reverse* buy operation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO4iYN2WecIp"
   },
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.0,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"buys\", \"brand\"),\n",
    "    rev_edge_types=(\"brand\", \"rev_buys\", \"user\"),\n",
    ")\n",
    "train_data, val_data, _ = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYhHcVl4ecK5",
    "outputId": "7a4000af-830b-4343-f24f-036d3460bb85"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJDILOsk-WDP"
   },
   "source": [
    "# Define the Loader\n",
    "\n",
    "We must also create a dataloader to generate training batches of the data. Neural networks rarely accept the whole dataset at once. More often, they gradually update their weights using portions of data (batches) until the whole dataset is processed.\n",
    "\n",
    "Some important parameters to give here:\n",
    "\n",
    "* `num_neighbors` - select max number of first-order neighbors and second-order neighbors\n",
    "* `neg_sampling_ratio` - similarly as before - define how many artificial negative edges should be generated for training.\n",
    "* `batch_size` - how many nodes (with their neighborhoods) we want to accept into the neural network in a given time\n",
    "* `shuffle=True` - we want to mix the ordering of training examples (it is shown to improve neural network quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-iSag63ecM9",
    "outputId": "a436ef03-f09b-4dd4-8683-99bc4bc7c60e"
   },
   "outputs": [],
   "source": [
    "edge_label_index = train_data[\"user\", \"buys\", \"brand\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"buys\", \"brand\"].edge_label\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"buys\", \"brand\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eTzahiK_lXX"
   },
   "source": [
    "# Create the GNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eh3sKbXZezJ2"
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        \"\"\"\n",
    "        Defines the architecture of our GNN, such as the type and number of layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #create 2 GraphSAGE layers:\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.num_users = data[\"user\"].num_nodes\n",
    "        self.num_brands = data[\"brand\"].num_nodes\n",
    "\n",
    "        #create untrained Embedding objects for users and brands. These embeddings will start to change during network training.\n",
    "        self.user_emb = torch.nn.Embedding(self.num_users, hidden_channels)\n",
    "        self.brand_emb = torch.nn.Embedding(self.num_brands, hidden_channels)\n",
    "        # Instantiate a homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        edge_label_index = data[\"user\", \"buys\", \"brand\"].edge_label_index\n",
    "\n",
    "        x_dict = self.encode(data)\n",
    "        pred = self.decode(x_dict[\"user\"], x_dict[\"brand\"], edge_label_index)\n",
    "        return pred\n",
    "\n",
    "    def encode(self, data: HeteroData) -> Tensor:\n",
    "        \"\"\"\n",
    "        Takes a HeteroData object (so, our graph or a part of it) and runs it thought our GNN.\n",
    "        We obtain a dictionary of node embeddings.\n",
    "        \"\"\"\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "          \"brand\": self.brand_emb(data[\"brand\"].node_id),\n",
    "        }\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "    def decode(self, x_user: Tensor, x_brand: Tensor, edge_label_index: np.array) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes similarity between given user and brand embeddings.\n",
    "        Similarity defines the \"relatedness\" of a given user with a given brand.\n",
    "        \"\"\"\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_brand = x_brand[edge_label_index[1]]\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_user * edge_feat_brand).sum(dim=-1)\n",
    "\n",
    "model = Model(hidden_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kJCDsxUBANgh",
    "outputId": "1604434a-3f71-4c2d-a3e5-19d692e02c23"
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "y = model(batch)\n",
    "\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkfmhZMLyoBE"
   },
   "source": [
    "# Training\n",
    "\n",
    "We train the model on a **link prediction** task. The training objective is to predict whether there is an edge between given nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NzORDWLezOt",
    "outputId": "227d776b-e3c9-4af5-ffd3-7620ac0e173b"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(1, 3):\n",
    "    total_loss = total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        ground_truth = sampled_data[\"user\", \"buys\", \"brand\"].edge_label\n",
    "\n",
    "        #this is a loss function for binary classification (0 = no edge between nodes exists, 1 = an edge between nodes exists)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss / total_examples:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjXG2V04e8wN"
   },
   "outputs": [],
   "source": [
    "target_brand_ids = unique_brands[unique_brands['brand'].isin(target_labels)]['mapped_brand'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GF8Jaoy1DXY"
   },
   "outputs": [],
   "source": [
    "target_brand_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4bVz8EU1FmP"
   },
   "outputs": [],
   "source": [
    "brand_dict = dict(zip(unique_brands['brand'].values, unique_brands['mapped_brand'].values))\n",
    "target_brand_ids = [brand_dict[brand] for brand in target_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g6DcrSw1_xE"
   },
   "outputs": [],
   "source": [
    "target_brand_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haqCDdXuBZfT"
   },
   "source": [
    "# Testing\n",
    "\n",
    "For testing, we need to create a new loader with no negative edges. We want to gather the trained embeddings of all users and brands.\n",
    "\n",
    "Note that these embeddings are **NOT** the nn.Embeddings objects. Rather, we want to get the vectors which originate after running our HeteroData through our GraphSAGE network. We treat these vectors as final, trained user and brand embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdN6LiEVe84F"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader_for_preds = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_label_index=((\"user\", \"buys\", \"brand\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63dohlqje86k"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "user_ids_set = set()\n",
    "user_ids = []\n",
    "user_emb = []\n",
    "\n",
    "brand_ids_set = set()\n",
    "brand_ids = []\n",
    "brand_emb = []\n",
    "\n",
    "for sampled_data in tqdm.tqdm(train_loader_for_preds):\n",
    "    with torch.no_grad():\n",
    "        sampled_data.to(device)\n",
    "        x_dict = model.encode(sampled_data)\n",
    "\n",
    "        u_ids = sampled_data[\"user\"].node_id\n",
    "        b_ids = sampled_data[\"brand\"].node_id\n",
    "\n",
    "        user_embeddings = x_dict[\"user\"]\n",
    "        brand_embeddings = x_dict[\"brand\"]\n",
    "\n",
    "        for u_id, u_emb in zip(u_ids, user_embeddings):\n",
    "            if u_id not in user_ids_set:\n",
    "                user_ids.append(u_id)\n",
    "                user_emb.append(u_emb)\n",
    "                user_ids_set.add(u_id)\n",
    "\n",
    "        for b_id, b_emb in zip(b_ids, brand_embeddings):\n",
    "            if b_id not in brand_ids_set:\n",
    "                brand_ids.append(b_id)\n",
    "                brand_emb.append(b_emb)\n",
    "                brand_ids_set.add(b_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQfXxVJ_ezRF"
   },
   "outputs": [],
   "source": [
    "target_brand_embeddings = [brand_embeddings[brand_ids.index(b_id)] for b_id in target_brand_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3mSmxJkfV6V"
   },
   "outputs": [],
   "source": [
    "target_brand_embeddings = torch.stack(target_brand_embeddings).cpu()\n",
    "user_embeddings = torch.stack(user_emb).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khEYBeiIfV8-"
   },
   "outputs": [],
   "source": [
    "user_ids = torch.tensor(user_ids, device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBpZgqbwCKx-"
   },
   "source": [
    "# Get the Final Predictions\n",
    "\n",
    "To get user and brand \"relatedness\" scores, we perform a dot product - similarly as during training. A high dot product value for a (user, brand) pair signifies a high relatedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXUJebRxfV_c"
   },
   "outputs": [],
   "source": [
    "preds = torch.matmul(user_embeddings, target_brand_embeddings.T.cpu()).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = targets[user_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Czk84Vyvfcrh"
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(ground_truths, preds)\n",
    "print(f\"Validation AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOGBfXE1HPuL"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "1. Change the neighborhood size in sampling to:\n",
    "* **10** first-order neighbors and **10** second-order neighbor,\n",
    "* **10** first-order neighbors, **10** second-order neighbors, **10** third-order neighbors, **10** fourth-order neighbors.\n",
    "\n",
    "For each configuration, start training the network and look at the estimated training time. You do not need to finish training, just look at how long the training is expected to take.\n",
    "Also, look at the network structure and see whether it changes between runs.\n",
    "\n",
    "**Q1:** Does the network structure change for the 2 configurations?\n",
    "\n",
    "**Q2:** How does training time change? Why does it change if network structure and batch size are the same?\n",
    "\n",
    "**Q3:** Does the estimated time keep even or suddenly jumps in the tqdm bar?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "cWOHuiZ1OtzH"
   },
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[10, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"buys\", \"brand\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[10, 10, 10, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"buys\", \"brand\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5UT8v4UOqIS"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Add an extra layer of SAGEConv (in total, you want to have 3 SAGEConv layers). Train the network and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "sTLhrzScPJg_"
   },
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        \"\"\"\n",
    "        Defines the architecture of our GNN, such as the type and number of layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #create 2 GraphSAGE layers:\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
